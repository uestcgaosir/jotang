{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "嵌入（embedding）在表征学习中是一个非常重要的一个概念。什么是嵌入呢？简而言之，嵌入就是一个低维稠密的向量。在图机器学习中，现在一个流行的范式是，将图中的每个节点映射为一个嵌入，然后将节点的嵌入输入到下游的机器学习任务中。图中每个节点的嵌入要反映出图的结构信息与节点的属性信息。怎么样得到节点的嵌入呢？我们可以通过随机游走或者深度学习的方法。由于以上两种方法得到嵌入的方法有些复杂，我们的task_1将从一个最简单的图嵌入学习方法入手，带你体会学习图节点嵌入学习的美妙！"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在task_1中,我们将为学习节点嵌入编写一个完整的pipeline。\n",
    "\n",
    "该图嵌入学习方法的总体思路是：先为图中的每一个节点分配一个随机嵌入，然后不断优化更新这个嵌入。\n",
    "\n",
    "优化具体实现过程是：我们将图中真实存在的边称作正边，设置标签为1，然后随机采样图中与正边数量相同的负边，设置标签为0，然后进行传统的监督学习任务。\n",
    "\n",
    "该task分为3个步骤：\n",
    "\n",
    "首先，我们将加载一个的经典图，[Karate Club Network](https://en.wikipedia.org/wiki/Zachary%27s_karate_club)。我们将探索该图的多个图统计信息。\n",
    "\n",
    "然后，再将图结构转换为PyTorch张量，这样我们就可以对图进行机器学习。\n",
    "\n",
    "最后，我们将完成第一个关于图节点嵌入的学习算法\n",
    "\n",
    "现在让我们开始吧！"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zachary's karate club Graph   \n",
    "我们先通过networkX包载入一个图[Karate Club Network](https://en.wikipedia.org/wiki/Zachary%27s_karate_club)，该图描述了空手道俱乐部34名成员的社交网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph named \"Zachary's Karate Club\" with 34 nodes and 78 edges\n",
      "<class 'networkx.classes.graph.Graph'>\n",
      "[(0, 1), (0, 2), (0, 3), (0, 4), (0, 5), (0, 6), (0, 7), (0, 8), (0, 10), (0, 11), (0, 12), (0, 13), (0, 17), (0, 19), (0, 21), (0, 31), (1, 2), (1, 3), (1, 7), (1, 13), (1, 17), (1, 19), (1, 21), (1, 30), (2, 3), (2, 7), (2, 8), (2, 9), (2, 13), (2, 27), (2, 28), (2, 32), (3, 7), (3, 12), (3, 13), (4, 6), (4, 10), (5, 6), (5, 10), (5, 16), (6, 16), (8, 30), (8, 32), (8, 33), (9, 33), (13, 33), (14, 32), (14, 33), (15, 32), (15, 33), (18, 32), (18, 33), (19, 33), (20, 32), (20, 33), (22, 32), (22, 33), (23, 25), (23, 27), (23, 29), (23, 32), (23, 33), (24, 25), (24, 27), (24, 31), (25, 31), (26, 29), (26, 33), (27, 33), (28, 31), (28, 33), (29, 32), (29, 33), (30, 32), (30, 33), (31, 32), (31, 33), (32, 33)]\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33]\n"
     ]
    }
   ],
   "source": [
    "import networkx as nx\n",
    "G = nx.karate_club_graph()\n",
    "\n",
    "print(G)\n",
    "print(type(G))\n",
    "print(G.edges)\n",
    "print(G.nodes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graph to Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  1,  1,\n",
      "          1,  1,  1,  1,  1,  1,  2,  2,  2,  2,  2,  2,  2,  2,  3,  3,  3,  4,\n",
      "          4,  5,  5,  5,  6,  8,  8,  8,  9, 13, 14, 14, 15, 15, 18, 18, 19, 20,\n",
      "         20, 22, 22, 23, 23, 23, 23, 23, 24, 24, 24, 25, 26, 26, 27, 28, 28, 29,\n",
      "         29, 30, 30, 31, 31, 32],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8, 10, 11, 12, 13, 17, 19, 21, 31,  2,  3,\n",
      "          7, 13, 17, 19, 21, 30,  3,  7,  8,  9, 13, 27, 28, 32,  7, 12, 13,  6,\n",
      "         10,  6, 10, 16, 16, 30, 32, 33, 33, 33, 32, 33, 32, 33, 32, 33, 33, 32,\n",
      "         33, 32, 33, 25, 27, 29, 32, 33, 25, 27, 31, 31, 29, 33, 33, 31, 33, 32,\n",
      "         33, 32, 33, 32, 33, 33]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "def graph_to_edge_list(G):\n",
    "  # 功能: 该函数返回图的edge list，输入为nxworkX\n",
    "  # 中的图。返回的edge_list是由元组组成的列表，其\n",
    "  # 中每个元组由边的两个节点组成\n",
    "\n",
    "  edge_list = []\n",
    "\n",
    "  ############# 在这儿写下你的代码吧 ############\n",
    "  for edge in G.edges():\n",
    "    edge_list.append(edge)\n",
    "  #########################################\n",
    "\n",
    "  return edge_list\n",
    "\n",
    "def edge_list_to_tensor(edge_list):\n",
    "  # 功能: 将edge list转换为张量，该张量的shape为[2 x len(edge_list)]\n",
    "\n",
    "  edge_index = torch.tensor([])\n",
    "\n",
    "  ############# 在这儿写下你的代码吧 ############\n",
    "  edge_index = torch.tensor(edge_list)\n",
    "  #########################################\n",
    "\n",
    "  return edge_index.t()\n",
    "\n",
    "import networkx as nx\n",
    "G = nx.karate_club_graph()\n",
    "print(edge_list_to_tensor(graph_to_edge_list(G)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# note：负边就是图中两个未连接的节点形成的边。正边是图中真实存在的边，\n",
    "# 正边由一个元组表示：（节点1，节点2），节点1与节点2相连；而负边是图\n",
    "# 中不存在的边，负边也由一个元组表示：（节点1，节点2），而节点1与节点\n",
    "# 2在图中不相连\n",
    "\n",
    "import random\n",
    "\n",
    "def sample_negative_edges(G, num_neg_samples):\n",
    "  # 功能: 随机采样num_neg_samples个负边。该函数\n",
    "  # 返回一个由负边（negative edge）构成的list\n",
    "  \n",
    "  neg_edge_list = []\n",
    "  ############# 在这儿写下你的代码吧 ############\n",
    "  node = list(G.nodes)\n",
    "  node_pairs = []\n",
    "  for i in range(len(node)):\n",
    "      for j in range(i+1, len(node)):\n",
    "          node_pairs.append((node[i], node[j]))\n",
    "\n",
    "    \n",
    "    # 从节点对中随机选择负边\n",
    "  while len(neg_edge_list) != num_neg_samples:  \n",
    "      pair = random.choice(node_pairs)\n",
    "      if not G.has_edge(*pair):  # 检查节点是否相连\n",
    "          neg_edge_list.append(pair)\n",
    "\n",
    "\n",
    "  #########################################\n",
    "  \n",
    "  return neg_edge_list\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "现在，是时候为我们的图创建节点嵌入矩阵了！我们希望空手道俱乐部网络中的每个节点嵌入的维度都是16维。并且我们规定初始嵌入中的每个数值都服从均匀分布。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding: Embedding(34, 16)\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "torch.manual_seed(1)\n",
    "\n",
    "def create_node_emb(num_node=34, embedding_dim=16):\n",
    "  # 功能: 创建一个节点嵌入矩阵，并随机化\n",
    "  emb = nn.Embedding(num_node, embedding_dim)\n",
    "  emb.weight.data = torch.rand(num_node, embedding_dim)\n",
    "  return emb\n",
    "\n",
    "emb = create_node_emb()\n",
    "\n",
    "# 打印嵌入层\n",
    "print(\"Embedding: {}\".format(emb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练过程\n",
    "from torch.optim import SGD\n",
    "import torch.nn as nn\n",
    "\n",
    "def accuracy(pred, label):\n",
    "  # 功能: 利用pred tensor (after sigmoid)和label tensor \n",
    "  # (torch.LongTensor)去计算预测准确率。如果预测的值大于\n",
    "  # 0.5被视为分类1，否则被视为分类0。准确率保留4位小数\n",
    "\n",
    "  accu = 0.0\n",
    "\n",
    "  ############# 在这儿写下你的代码吧 ############\n",
    "  pred_label = (pred > 0.5).long()\n",
    "  accu = (pred_label == label).sum().item()/len(label)\n",
    "  accu = round(accu , 4)\n",
    "\n",
    "  #########################################\n",
    "\n",
    "  return accu\n",
    "\n",
    "def train(emb, loss_fn, sigmoid, train_label, train_edge):\n",
    "  # 功能: 训练节点嵌入层 \n",
    "  # 提示：\n",
    "  # (1) 得到train_edge的nodes的嵌入\n",
    "  # (2) 将train_edge中的节点对的嵌入做点积\n",
    "  # (3) 将点积输入sigmoid函数得到sigmoid output\n",
    "  # (4) 将sigmoid output和标签输入输入loss_fn中算损失\n",
    "  # (5) 每轮（epoch）训练将打印ccuracy和loss\n",
    "  # (6) 使用损失函数与优化器更新每个节点的embedding\n",
    "\n",
    "  epochs = 500\n",
    "  learning_rate = 0.1\n",
    "\n",
    "  optimizer = SGD(emb.parameters(), lr=learning_rate, momentum=0.9)\n",
    "\n",
    "  for i in range(epochs):\n",
    "    ############# 在这儿写下你的代码吧 ############\n",
    "    optimizer.zero_grad()\n",
    "    #(1)\n",
    "    embednode = emb(train_edge)\n",
    "    #(2)\n",
    "    dot = embednode[0].mul(embednode[1])\n",
    "    dot = torch.sum(dot,1)\n",
    "    #(3)\n",
    "    sigmoid_output = sigmoid(dot)\n",
    "    #(4)\n",
    "    loss = loss_fn(sigmoid_output, train_label)\n",
    "    #(5)\n",
    "    accu = accuracy(sigmoid_output,train_label)\n",
    "    print(f\"Epoch {i+1}, Accuracy: {accu}, Loss: {loss.item()}\")\n",
    "    #(6)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    #########################################\n",
    "  \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Accuracy: 0.5, Loss: 2.0075459480285645\n",
      "Epoch 2, Accuracy: 0.5, Loss: 1.9931122064590454\n",
      "Epoch 3, Accuracy: 0.5, Loss: 1.9659230709075928\n",
      "Epoch 4, Accuracy: 0.5, Loss: 1.9276773929595947\n",
      "Epoch 5, Accuracy: 0.5, Loss: 1.880060076713562\n",
      "Epoch 6, Accuracy: 0.5, Loss: 1.8247097730636597\n",
      "Epoch 7, Accuracy: 0.5, Loss: 1.763195276260376\n",
      "Epoch 8, Accuracy: 0.5, Loss: 1.6970016956329346\n",
      "Epoch 9, Accuracy: 0.5, Loss: 1.6275155544281006\n",
      "Epoch 10, Accuracy: 0.5, Loss: 1.5560158491134644\n",
      "Epoch 11, Accuracy: 0.5, Loss: 1.483666181564331\n",
      "Epoch 12, Accuracy: 0.5, Loss: 1.411506175994873\n",
      "Epoch 13, Accuracy: 0.5, Loss: 1.3404464721679688\n",
      "Epoch 14, Accuracy: 0.5, Loss: 1.2712653875350952\n",
      "Epoch 15, Accuracy: 0.5, Loss: 1.2046048641204834\n",
      "Epoch 16, Accuracy: 0.5, Loss: 1.1409746408462524\n",
      "Epoch 17, Accuracy: 0.5, Loss: 1.0807552337646484\n",
      "Epoch 18, Accuracy: 0.5064, Loss: 1.0242061614990234\n",
      "Epoch 19, Accuracy: 0.5192, Loss: 0.9714784026145935\n",
      "Epoch 20, Accuracy: 0.5192, Loss: 0.9226255416870117\n",
      "Epoch 21, Accuracy: 0.5192, Loss: 0.8776198029518127\n",
      "Epoch 22, Accuracy: 0.5256, Loss: 0.8363659977912903\n",
      "Epoch 23, Accuracy: 0.5321, Loss: 0.7987163662910461\n",
      "Epoch 24, Accuracy: 0.5321, Loss: 0.7644835114479065\n",
      "Epoch 25, Accuracy: 0.5321, Loss: 0.7334538698196411\n",
      "Epoch 26, Accuracy: 0.5449, Loss: 0.7053968906402588\n",
      "Epoch 27, Accuracy: 0.5769, Loss: 0.6800750494003296\n",
      "Epoch 28, Accuracy: 0.5897, Loss: 0.657249927520752\n",
      "Epoch 29, Accuracy: 0.6026, Loss: 0.6366891860961914\n",
      "Epoch 30, Accuracy: 0.6218, Loss: 0.6181696653366089\n",
      "Epoch 31, Accuracy: 0.6346, Loss: 0.6014803647994995\n",
      "Epoch 32, Accuracy: 0.641, Loss: 0.5864247679710388\n",
      "Epoch 33, Accuracy: 0.6603, Loss: 0.5728213787078857\n",
      "Epoch 34, Accuracy: 0.6731, Loss: 0.5605042576789856\n",
      "Epoch 35, Accuracy: 0.6987, Loss: 0.5493229627609253\n",
      "Epoch 36, Accuracy: 0.7051, Loss: 0.5391417741775513\n",
      "Epoch 37, Accuracy: 0.7244, Loss: 0.5298389196395874\n",
      "Epoch 38, Accuracy: 0.7372, Loss: 0.5213061571121216\n",
      "Epoch 39, Accuracy: 0.7436, Loss: 0.513447105884552\n",
      "Epoch 40, Accuracy: 0.7564, Loss: 0.5061765909194946\n",
      "Epoch 41, Accuracy: 0.7564, Loss: 0.499419629573822\n",
      "Epoch 42, Accuracy: 0.7692, Loss: 0.4931102693080902\n",
      "Epoch 43, Accuracy: 0.7949, Loss: 0.48719069361686707\n",
      "Epoch 44, Accuracy: 0.8013, Loss: 0.48161041736602783\n",
      "Epoch 45, Accuracy: 0.7949, Loss: 0.47632530331611633\n",
      "Epoch 46, Accuracy: 0.7949, Loss: 0.47129693627357483\n",
      "Epoch 47, Accuracy: 0.8013, Loss: 0.466492235660553\n",
      "Epoch 48, Accuracy: 0.8013, Loss: 0.4618820250034332\n",
      "Epoch 49, Accuracy: 0.8077, Loss: 0.4574414789676666\n",
      "Epoch 50, Accuracy: 0.8205, Loss: 0.4531489610671997\n",
      "Epoch 51, Accuracy: 0.8269, Loss: 0.4489858150482178\n",
      "Epoch 52, Accuracy: 0.8269, Loss: 0.4449359178543091\n",
      "Epoch 53, Accuracy: 0.8333, Loss: 0.4409855604171753\n",
      "Epoch 54, Accuracy: 0.8397, Loss: 0.43712273240089417\n",
      "Epoch 55, Accuracy: 0.8526, Loss: 0.43333739042282104\n",
      "Epoch 56, Accuracy: 0.8526, Loss: 0.4296206831932068\n",
      "Epoch 57, Accuracy: 0.859, Loss: 0.42596518993377686\n",
      "Epoch 58, Accuracy: 0.8654, Loss: 0.4223645031452179\n",
      "Epoch 59, Accuracy: 0.859, Loss: 0.4188131093978882\n",
      "Epoch 60, Accuracy: 0.859, Loss: 0.41530632972717285\n",
      "Epoch 61, Accuracy: 0.859, Loss: 0.4118402302265167\n",
      "Epoch 62, Accuracy: 0.8654, Loss: 0.40841132402420044\n",
      "Epoch 63, Accuracy: 0.8782, Loss: 0.4050166606903076\n",
      "Epoch 64, Accuracy: 0.8782, Loss: 0.4016537070274353\n",
      "Epoch 65, Accuracy: 0.8782, Loss: 0.39832040667533875\n",
      "Epoch 66, Accuracy: 0.8782, Loss: 0.39501476287841797\n",
      "Epoch 67, Accuracy: 0.8846, Loss: 0.3917352855205536\n",
      "Epoch 68, Accuracy: 0.8846, Loss: 0.38848060369491577\n",
      "Epoch 69, Accuracy: 0.8846, Loss: 0.38524946570396423\n",
      "Epoch 70, Accuracy: 0.8846, Loss: 0.38204076886177063\n",
      "Epoch 71, Accuracy: 0.891, Loss: 0.37885376811027527\n",
      "Epoch 72, Accuracy: 0.891, Loss: 0.37568753957748413\n",
      "Epoch 73, Accuracy: 0.891, Loss: 0.37254130840301514\n",
      "Epoch 74, Accuracy: 0.8974, Loss: 0.36941465735435486\n",
      "Epoch 75, Accuracy: 0.891, Loss: 0.3663068413734436\n",
      "Epoch 76, Accuracy: 0.891, Loss: 0.3632175028324127\n",
      "Epoch 77, Accuracy: 0.9038, Loss: 0.36014610528945923\n",
      "Epoch 78, Accuracy: 0.9038, Loss: 0.35709232091903687\n",
      "Epoch 79, Accuracy: 0.9038, Loss: 0.354055792093277\n",
      "Epoch 80, Accuracy: 0.9038, Loss: 0.3510361909866333\n",
      "Epoch 81, Accuracy: 0.9103, Loss: 0.34803318977355957\n",
      "Epoch 82, Accuracy: 0.9103, Loss: 0.34504666924476624\n",
      "Epoch 83, Accuracy: 0.9167, Loss: 0.34207624197006226\n",
      "Epoch 84, Accuracy: 0.9167, Loss: 0.33912184834480286\n",
      "Epoch 85, Accuracy: 0.9167, Loss: 0.33618324995040894\n",
      "Epoch 86, Accuracy: 0.9167, Loss: 0.33326032757759094\n",
      "Epoch 87, Accuracy: 0.9231, Loss: 0.33035290241241455\n",
      "Epoch 88, Accuracy: 0.9231, Loss: 0.3274609446525574\n",
      "Epoch 89, Accuracy: 0.9295, Loss: 0.32458433508872986\n",
      "Epoch 90, Accuracy: 0.9295, Loss: 0.3217230439186096\n",
      "Epoch 91, Accuracy: 0.9295, Loss: 0.3188769817352295\n",
      "Epoch 92, Accuracy: 0.9295, Loss: 0.3160460889339447\n",
      "Epoch 93, Accuracy: 0.9295, Loss: 0.3132304251194\n",
      "Epoch 94, Accuracy: 0.9359, Loss: 0.31042996048927307\n",
      "Epoch 95, Accuracy: 0.9359, Loss: 0.30764472484588623\n",
      "Epoch 96, Accuracy: 0.9359, Loss: 0.3048746883869171\n",
      "Epoch 97, Accuracy: 0.9423, Loss: 0.3021199703216553\n",
      "Epoch 98, Accuracy: 0.9423, Loss: 0.2993805706501007\n",
      "Epoch 99, Accuracy: 0.9487, Loss: 0.29665660858154297\n",
      "Epoch 100, Accuracy: 0.9551, Loss: 0.29394811391830444\n",
      "Epoch 101, Accuracy: 0.9551, Loss: 0.2912551760673523\n",
      "Epoch 102, Accuracy: 0.9551, Loss: 0.2885779142379761\n",
      "Epoch 103, Accuracy: 0.9551, Loss: 0.28591638803482056\n",
      "Epoch 104, Accuracy: 0.9615, Loss: 0.2832707166671753\n",
      "Epoch 105, Accuracy: 0.9679, Loss: 0.28064101934432983\n",
      "Epoch 106, Accuracy: 0.9679, Loss: 0.27802741527557373\n",
      "Epoch 107, Accuracy: 0.9679, Loss: 0.2754300534725189\n",
      "Epoch 108, Accuracy: 0.9679, Loss: 0.2728489637374878\n",
      "Epoch 109, Accuracy: 0.9744, Loss: 0.27028435468673706\n",
      "Epoch 110, Accuracy: 0.9744, Loss: 0.2677363455295563\n",
      "Epoch 111, Accuracy: 0.9808, Loss: 0.2652049958705902\n",
      "Epoch 112, Accuracy: 0.9808, Loss: 0.2626905143260956\n",
      "Epoch 113, Accuracy: 0.9808, Loss: 0.26019299030303955\n",
      "Epoch 114, Accuracy: 0.9808, Loss: 0.25771254301071167\n",
      "Epoch 115, Accuracy: 0.9808, Loss: 0.2552493214607239\n",
      "Epoch 116, Accuracy: 0.9808, Loss: 0.25280338525772095\n",
      "Epoch 117, Accuracy: 0.9808, Loss: 0.2503749430179596\n",
      "Epoch 118, Accuracy: 0.9872, Loss: 0.2479640543460846\n",
      "Epoch 119, Accuracy: 0.9872, Loss: 0.2455708384513855\n",
      "Epoch 120, Accuracy: 0.9936, Loss: 0.24319538474082947\n",
      "Epoch 121, Accuracy: 0.9936, Loss: 0.24083785712718964\n",
      "Epoch 122, Accuracy: 0.9936, Loss: 0.23849830031394958\n",
      "Epoch 123, Accuracy: 0.9936, Loss: 0.23617680370807648\n",
      "Epoch 124, Accuracy: 0.9936, Loss: 0.23387351632118225\n",
      "Epoch 125, Accuracy: 0.9936, Loss: 0.2315884679555893\n",
      "Epoch 126, Accuracy: 0.9936, Loss: 0.22932179272174835\n",
      "Epoch 127, Accuracy: 0.9936, Loss: 0.22707350552082062\n",
      "Epoch 128, Accuracy: 0.9936, Loss: 0.22484368085861206\n",
      "Epoch 129, Accuracy: 0.9936, Loss: 0.22263240814208984\n",
      "Epoch 130, Accuracy: 0.9936, Loss: 0.22043974697589874\n",
      "Epoch 131, Accuracy: 0.9936, Loss: 0.21826572716236115\n",
      "Epoch 132, Accuracy: 0.9936, Loss: 0.21611037850379944\n",
      "Epoch 133, Accuracy: 0.9936, Loss: 0.21397380530834198\n",
      "Epoch 134, Accuracy: 0.9936, Loss: 0.2118559628725052\n",
      "Epoch 135, Accuracy: 0.9936, Loss: 0.20975695550441742\n",
      "Epoch 136, Accuracy: 0.9936, Loss: 0.2076767235994339\n",
      "Epoch 137, Accuracy: 0.9936, Loss: 0.2056153118610382\n",
      "Epoch 138, Accuracy: 0.9936, Loss: 0.20357277989387512\n",
      "Epoch 139, Accuracy: 1.0, Loss: 0.20154908299446106\n",
      "Epoch 140, Accuracy: 1.0, Loss: 0.19954422116279602\n",
      "Epoch 141, Accuracy: 1.0, Loss: 0.19755816459655762\n",
      "Epoch 142, Accuracy: 1.0, Loss: 0.19559097290039062\n",
      "Epoch 143, Accuracy: 1.0, Loss: 0.19364260137081146\n",
      "Epoch 144, Accuracy: 1.0, Loss: 0.19171297550201416\n",
      "Epoch 145, Accuracy: 1.0, Loss: 0.1898021250963211\n",
      "Epoch 146, Accuracy: 1.0, Loss: 0.18791000545024872\n",
      "Epoch 147, Accuracy: 1.0, Loss: 0.18603655695915222\n",
      "Epoch 148, Accuracy: 1.0, Loss: 0.18418176472187042\n",
      "Epoch 149, Accuracy: 1.0, Loss: 0.18234556913375854\n",
      "Epoch 150, Accuracy: 1.0, Loss: 0.18052789568901062\n",
      "Epoch 151, Accuracy: 1.0, Loss: 0.17872872948646545\n",
      "Epoch 152, Accuracy: 1.0, Loss: 0.17694801092147827\n",
      "Epoch 153, Accuracy: 1.0, Loss: 0.17518562078475952\n",
      "Epoch 154, Accuracy: 1.0, Loss: 0.173441544175148\n",
      "Epoch 155, Accuracy: 1.0, Loss: 0.17171570658683777\n",
      "Epoch 156, Accuracy: 1.0, Loss: 0.17000797390937805\n",
      "Epoch 157, Accuracy: 1.0, Loss: 0.16831833124160767\n",
      "Epoch 158, Accuracy: 1.0, Loss: 0.16664667427539825\n",
      "Epoch 159, Accuracy: 1.0, Loss: 0.16499291360378265\n",
      "Epoch 160, Accuracy: 1.0, Loss: 0.1633569449186325\n",
      "Epoch 161, Accuracy: 1.0, Loss: 0.16173870861530304\n",
      "Epoch 162, Accuracy: 1.0, Loss: 0.1601380854845047\n",
      "Epoch 163, Accuracy: 1.0, Loss: 0.15855495631694794\n",
      "Epoch 164, Accuracy: 1.0, Loss: 0.15698926150798798\n",
      "Epoch 165, Accuracy: 1.0, Loss: 0.15544088184833527\n",
      "Epoch 166, Accuracy: 1.0, Loss: 0.15390968322753906\n",
      "Epoch 167, Accuracy: 1.0, Loss: 0.152395561337471\n",
      "Epoch 168, Accuracy: 1.0, Loss: 0.15089844167232513\n",
      "Epoch 169, Accuracy: 1.0, Loss: 0.1494181752204895\n",
      "Epoch 170, Accuracy: 1.0, Loss: 0.14795462787151337\n",
      "Epoch 171, Accuracy: 1.0, Loss: 0.14650771021842957\n",
      "Epoch 172, Accuracy: 1.0, Loss: 0.14507733285427094\n",
      "Epoch 173, Accuracy: 1.0, Loss: 0.14366327226161957\n",
      "Epoch 174, Accuracy: 1.0, Loss: 0.14226548373699188\n",
      "Epoch 175, Accuracy: 1.0, Loss: 0.14088378846645355\n",
      "Epoch 176, Accuracy: 1.0, Loss: 0.13951809704303741\n",
      "Epoch 177, Accuracy: 1.0, Loss: 0.13816829025745392\n",
      "Epoch 178, Accuracy: 1.0, Loss: 0.13683417439460754\n",
      "Epoch 179, Accuracy: 1.0, Loss: 0.13551566004753113\n",
      "Epoch 180, Accuracy: 1.0, Loss: 0.13421258330345154\n",
      "Epoch 181, Accuracy: 1.0, Loss: 0.13292482495307922\n",
      "Epoch 182, Accuracy: 1.0, Loss: 0.13165225088596344\n",
      "Epoch 183, Accuracy: 1.0, Loss: 0.13039471209049225\n",
      "Epoch 184, Accuracy: 1.0, Loss: 0.1291520893573761\n",
      "Epoch 185, Accuracy: 1.0, Loss: 0.12792420387268066\n",
      "Epoch 186, Accuracy: 1.0, Loss: 0.1267109364271164\n",
      "Epoch 187, Accuracy: 1.0, Loss: 0.12551215291023254\n",
      "Epoch 188, Accuracy: 1.0, Loss: 0.12432768195867538\n",
      "Epoch 189, Accuracy: 1.0, Loss: 0.12315740436315536\n",
      "Epoch 190, Accuracy: 1.0, Loss: 0.12200117111206055\n",
      "Epoch 191, Accuracy: 1.0, Loss: 0.1208588257431984\n",
      "Epoch 192, Accuracy: 1.0, Loss: 0.11973022669553757\n",
      "Epoch 193, Accuracy: 1.0, Loss: 0.11861523240804672\n",
      "Epoch 194, Accuracy: 1.0, Loss: 0.11751371622085571\n",
      "Epoch 195, Accuracy: 1.0, Loss: 0.11642549186944962\n",
      "Epoch 196, Accuracy: 1.0, Loss: 0.11535044014453888\n",
      "Epoch 197, Accuracy: 1.0, Loss: 0.11428841203451157\n",
      "Epoch 198, Accuracy: 1.0, Loss: 0.11323926597833633\n",
      "Epoch 199, Accuracy: 1.0, Loss: 0.11220283806324005\n",
      "Epoch 200, Accuracy: 1.0, Loss: 0.11117899417877197\n",
      "Epoch 201, Accuracy: 1.0, Loss: 0.11016761511564255\n",
      "Epoch 202, Accuracy: 1.0, Loss: 0.10916851460933685\n",
      "Epoch 203, Accuracy: 1.0, Loss: 0.10818155854940414\n",
      "Epoch 204, Accuracy: 1.0, Loss: 0.10720662772655487\n",
      "Epoch 205, Accuracy: 1.0, Loss: 0.1062435582280159\n",
      "Epoch 206, Accuracy: 1.0, Loss: 0.10529222339391708\n",
      "Epoch 207, Accuracy: 1.0, Loss: 0.10435245931148529\n",
      "Epoch 208, Accuracy: 1.0, Loss: 0.10342414677143097\n",
      "Epoch 209, Accuracy: 1.0, Loss: 0.10250711441040039\n",
      "Epoch 210, Accuracy: 1.0, Loss: 0.1016012579202652\n",
      "Epoch 211, Accuracy: 1.0, Loss: 0.10070642083883286\n",
      "Epoch 212, Accuracy: 1.0, Loss: 0.09982246905565262\n",
      "Epoch 213, Accuracy: 1.0, Loss: 0.09894927591085434\n",
      "Epoch 214, Accuracy: 1.0, Loss: 0.09808667749166489\n",
      "Epoch 215, Accuracy: 1.0, Loss: 0.09723455458879471\n",
      "Epoch 216, Accuracy: 1.0, Loss: 0.09639278799295425\n",
      "Epoch 217, Accuracy: 1.0, Loss: 0.09556123614311218\n",
      "Epoch 218, Accuracy: 1.0, Loss: 0.09473975747823715\n",
      "Epoch 219, Accuracy: 1.0, Loss: 0.09392821788787842\n",
      "Epoch 220, Accuracy: 1.0, Loss: 0.09312650561332703\n",
      "Epoch 221, Accuracy: 1.0, Loss: 0.09233449399471283\n",
      "Epoch 222, Accuracy: 1.0, Loss: 0.0915520191192627\n",
      "Epoch 223, Accuracy: 1.0, Loss: 0.09077899903059006\n",
      "Epoch 224, Accuracy: 1.0, Loss: 0.09001529961824417\n",
      "Epoch 225, Accuracy: 1.0, Loss: 0.0892607718706131\n",
      "Epoch 226, Accuracy: 1.0, Loss: 0.08851532638072968\n",
      "Epoch 227, Accuracy: 1.0, Loss: 0.08777881413698196\n",
      "Epoch 228, Accuracy: 1.0, Loss: 0.08705111593008041\n",
      "Epoch 229, Accuracy: 1.0, Loss: 0.08633214235305786\n",
      "Epoch 230, Accuracy: 1.0, Loss: 0.08562176674604416\n",
      "Epoch 231, Accuracy: 1.0, Loss: 0.08491985499858856\n",
      "Epoch 232, Accuracy: 1.0, Loss: 0.08422630280256271\n",
      "Epoch 233, Accuracy: 1.0, Loss: 0.08354097604751587\n",
      "Epoch 234, Accuracy: 1.0, Loss: 0.08286380767822266\n",
      "Epoch 235, Accuracy: 1.0, Loss: 0.08219465613365173\n",
      "Epoch 236, Accuracy: 1.0, Loss: 0.08153342455625534\n",
      "Epoch 237, Accuracy: 1.0, Loss: 0.08087997883558273\n",
      "Epoch 238, Accuracy: 1.0, Loss: 0.08023425191640854\n",
      "Epoch 239, Accuracy: 1.0, Loss: 0.07959611713886261\n",
      "Epoch 240, Accuracy: 1.0, Loss: 0.07896546274423599\n",
      "Epoch 241, Accuracy: 1.0, Loss: 0.07834219932556152\n",
      "Epoch 242, Accuracy: 1.0, Loss: 0.07772621512413025\n",
      "Epoch 243, Accuracy: 1.0, Loss: 0.0771174281835556\n",
      "Epoch 244, Accuracy: 1.0, Loss: 0.07651571184396744\n",
      "Epoch 245, Accuracy: 1.0, Loss: 0.07592100650072098\n",
      "Epoch 246, Accuracy: 1.0, Loss: 0.07533317059278488\n",
      "Epoch 247, Accuracy: 1.0, Loss: 0.07475214451551437\n",
      "Epoch 248, Accuracy: 1.0, Loss: 0.0741778314113617\n",
      "Epoch 249, Accuracy: 1.0, Loss: 0.07361011207103729\n",
      "Epoch 250, Accuracy: 1.0, Loss: 0.0730489119887352\n",
      "Epoch 251, Accuracy: 1.0, Loss: 0.07249415665864944\n",
      "Epoch 252, Accuracy: 1.0, Loss: 0.07194573432207108\n",
      "Epoch 253, Accuracy: 1.0, Loss: 0.07140357047319412\n",
      "Epoch 254, Accuracy: 1.0, Loss: 0.07086756080389023\n",
      "Epoch 255, Accuracy: 1.0, Loss: 0.07033766061067581\n",
      "Epoch 256, Accuracy: 1.0, Loss: 0.06981374323368073\n",
      "Epoch 257, Accuracy: 1.0, Loss: 0.0692957416176796\n",
      "Epoch 258, Accuracy: 1.0, Loss: 0.06878357380628586\n",
      "Epoch 259, Accuracy: 1.0, Loss: 0.06827717274427414\n",
      "Epoch 260, Accuracy: 1.0, Loss: 0.06777643412351608\n",
      "Epoch 261, Accuracy: 1.0, Loss: 0.06728129833936691\n",
      "Epoch 262, Accuracy: 1.0, Loss: 0.06679169088602066\n",
      "Epoch 263, Accuracy: 1.0, Loss: 0.06630751490592957\n",
      "Epoch 264, Accuracy: 1.0, Loss: 0.06582871824502945\n",
      "Epoch 265, Accuracy: 1.0, Loss: 0.06535521894693375\n",
      "Epoch 266, Accuracy: 1.0, Loss: 0.06488693505525589\n",
      "Epoch 267, Accuracy: 1.0, Loss: 0.0644238144159317\n",
      "Epoch 268, Accuracy: 1.0, Loss: 0.06396577507257462\n",
      "Epoch 269, Accuracy: 1.0, Loss: 0.06351274251937866\n",
      "Epoch 270, Accuracy: 1.0, Loss: 0.06306465715169907\n",
      "Epoch 271, Accuracy: 1.0, Loss: 0.06262143701314926\n",
      "Epoch 272, Accuracy: 1.0, Loss: 0.06218304857611656\n",
      "Epoch 273, Accuracy: 1.0, Loss: 0.061749398708343506\n",
      "Epoch 274, Accuracy: 1.0, Loss: 0.06132043898105621\n",
      "Epoch 275, Accuracy: 1.0, Loss: 0.06089607998728752\n",
      "Epoch 276, Accuracy: 1.0, Loss: 0.060476284474134445\n",
      "Epoch 277, Accuracy: 1.0, Loss: 0.06006098911166191\n",
      "Epoch 278, Accuracy: 1.0, Loss: 0.05965012311935425\n",
      "Epoch 279, Accuracy: 1.0, Loss: 0.05924362316727638\n",
      "Epoch 280, Accuracy: 1.0, Loss: 0.05884145572781563\n",
      "Epoch 281, Accuracy: 1.0, Loss: 0.05844353511929512\n",
      "Epoch 282, Accuracy: 1.0, Loss: 0.05804981291294098\n",
      "Epoch 283, Accuracy: 1.0, Loss: 0.057660236954689026\n",
      "Epoch 284, Accuracy: 1.0, Loss: 0.05727475881576538\n",
      "Epoch 285, Accuracy: 1.0, Loss: 0.056893300265073776\n",
      "Epoch 286, Accuracy: 1.0, Loss: 0.056515827775001526\n",
      "Epoch 287, Accuracy: 1.0, Loss: 0.05614227429032326\n",
      "Epoch 288, Accuracy: 1.0, Loss: 0.05577261000871658\n",
      "Epoch 289, Accuracy: 1.0, Loss: 0.055406760424375534\n",
      "Epoch 290, Accuracy: 1.0, Loss: 0.055044692009687424\n",
      "Epoch 291, Accuracy: 1.0, Loss: 0.054686348885297775\n",
      "Epoch 292, Accuracy: 1.0, Loss: 0.05433167517185211\n",
      "Epoch 293, Accuracy: 1.0, Loss: 0.05398062989115715\n",
      "Epoch 294, Accuracy: 1.0, Loss: 0.05363317206501961\n",
      "Epoch 295, Accuracy: 1.0, Loss: 0.05328923091292381\n",
      "Epoch 296, Accuracy: 1.0, Loss: 0.05294879153370857\n",
      "Epoch 297, Accuracy: 1.0, Loss: 0.052611786872148514\n",
      "Epoch 298, Accuracy: 1.0, Loss: 0.052278175950050354\n",
      "Epoch 299, Accuracy: 1.0, Loss: 0.05194791778922081\n",
      "Epoch 300, Accuracy: 1.0, Loss: 0.0516209676861763\n",
      "Epoch 301, Accuracy: 1.0, Loss: 0.05129728466272354\n",
      "Epoch 302, Accuracy: 1.0, Loss: 0.05097683146595955\n",
      "Epoch 303, Accuracy: 1.0, Loss: 0.05065954476594925\n",
      "Epoch 304, Accuracy: 1.0, Loss: 0.05034541338682175\n",
      "Epoch 305, Accuracy: 1.0, Loss: 0.050034377723932266\n",
      "Epoch 306, Accuracy: 1.0, Loss: 0.04972640424966812\n",
      "Epoch 307, Accuracy: 1.0, Loss: 0.04942145198583603\n",
      "Epoch 308, Accuracy: 1.0, Loss: 0.0491194874048233\n",
      "Epoch 309, Accuracy: 1.0, Loss: 0.04882046952843666\n",
      "Epoch 310, Accuracy: 1.0, Loss: 0.04852435365319252\n",
      "Epoch 311, Accuracy: 1.0, Loss: 0.04823111370205879\n",
      "Epoch 312, Accuracy: 1.0, Loss: 0.047940704971551895\n",
      "Epoch 313, Accuracy: 1.0, Loss: 0.04765309765934944\n",
      "Epoch 314, Accuracy: 1.0, Loss: 0.047368261963129044\n",
      "Epoch 315, Accuracy: 1.0, Loss: 0.04708614572882652\n",
      "Epoch 316, Accuracy: 1.0, Loss: 0.046806734055280685\n",
      "Epoch 317, Accuracy: 1.0, Loss: 0.04652997851371765\n",
      "Epoch 318, Accuracy: 1.0, Loss: 0.04625585675239563\n",
      "Epoch 319, Accuracy: 1.0, Loss: 0.04598432034254074\n",
      "Epoch 320, Accuracy: 1.0, Loss: 0.04571535065770149\n",
      "Epoch 321, Accuracy: 1.0, Loss: 0.04544892907142639\n",
      "Epoch 322, Accuracy: 1.0, Loss: 0.045184992253780365\n",
      "Epoch 323, Accuracy: 1.0, Loss: 0.044923532754182816\n",
      "Epoch 324, Accuracy: 1.0, Loss: 0.04466450586915016\n",
      "Epoch 325, Accuracy: 1.0, Loss: 0.04440789297223091\n",
      "Epoch 326, Accuracy: 1.0, Loss: 0.044153667986392975\n",
      "Epoch 327, Accuracy: 1.0, Loss: 0.04390179365873337\n",
      "Epoch 328, Accuracy: 1.0, Loss: 0.04365222901105881\n",
      "Epoch 329, Accuracy: 1.0, Loss: 0.043404970318078995\n",
      "Epoch 330, Accuracy: 1.0, Loss: 0.04315996915102005\n",
      "Epoch 331, Accuracy: 1.0, Loss: 0.04291722550988197\n",
      "Epoch 332, Accuracy: 1.0, Loss: 0.04267667606472969\n",
      "Epoch 333, Accuracy: 1.0, Loss: 0.0424383245408535\n",
      "Epoch 334, Accuracy: 1.0, Loss: 0.04220212250947952\n",
      "Epoch 335, Accuracy: 1.0, Loss: 0.04196806252002716\n",
      "Epoch 336, Accuracy: 1.0, Loss: 0.04173610359430313\n",
      "Epoch 337, Accuracy: 1.0, Loss: 0.04150622710585594\n",
      "Epoch 338, Accuracy: 1.0, Loss: 0.0412784218788147\n",
      "Epoch 339, Accuracy: 1.0, Loss: 0.041052643209695816\n",
      "Epoch 340, Accuracy: 1.0, Loss: 0.04082886874675751\n",
      "Epoch 341, Accuracy: 1.0, Loss: 0.040607087314128876\n",
      "Epoch 342, Accuracy: 1.0, Loss: 0.040387265384197235\n",
      "Epoch 343, Accuracy: 1.0, Loss: 0.04016938805580139\n",
      "Epoch 344, Accuracy: 1.0, Loss: 0.039953429251909256\n",
      "Epoch 345, Accuracy: 1.0, Loss: 0.03973935544490814\n",
      "Epoch 346, Accuracy: 1.0, Loss: 0.03952715918421745\n",
      "Epoch 347, Accuracy: 1.0, Loss: 0.0393168181180954\n",
      "Epoch 348, Accuracy: 1.0, Loss: 0.03910829499363899\n",
      "Epoch 349, Accuracy: 1.0, Loss: 0.038901593536138535\n",
      "Epoch 350, Accuracy: 1.0, Loss: 0.03869667649269104\n",
      "Epoch 351, Accuracy: 1.0, Loss: 0.03849351778626442\n",
      "Epoch 352, Accuracy: 1.0, Loss: 0.038292109966278076\n",
      "Epoch 353, Accuracy: 1.0, Loss: 0.03809243440628052\n",
      "Epoch 354, Accuracy: 1.0, Loss: 0.03789446875452995\n",
      "Epoch 355, Accuracy: 1.0, Loss: 0.0376981757581234\n",
      "Epoch 356, Accuracy: 1.0, Loss: 0.03750355914235115\n",
      "Epoch 357, Accuracy: 1.0, Loss: 0.03731058910489082\n",
      "Epoch 358, Accuracy: 1.0, Loss: 0.03711925819516182\n",
      "Epoch 359, Accuracy: 1.0, Loss: 0.036929529160261154\n",
      "Epoch 360, Accuracy: 1.0, Loss: 0.03674139827489853\n",
      "Epoch 361, Accuracy: 1.0, Loss: 0.03655484318733215\n",
      "Epoch 362, Accuracy: 1.0, Loss: 0.036369841545820236\n",
      "Epoch 363, Accuracy: 1.0, Loss: 0.03618638962507248\n",
      "Epoch 364, Accuracy: 1.0, Loss: 0.036004457622766495\n",
      "Epoch 365, Accuracy: 1.0, Loss: 0.03582403436303139\n",
      "Epoch 366, Accuracy: 1.0, Loss: 0.035645101219415665\n",
      "Epoch 367, Accuracy: 1.0, Loss: 0.03546763211488724\n",
      "Epoch 368, Accuracy: 1.0, Loss: 0.035291630774736404\n",
      "Epoch 369, Accuracy: 1.0, Loss: 0.035117071121931076\n",
      "Epoch 370, Accuracy: 1.0, Loss: 0.03494393453001976\n",
      "Epoch 371, Accuracy: 1.0, Loss: 0.03477220982313156\n",
      "Epoch 372, Accuracy: 1.0, Loss: 0.03460186719894409\n",
      "Epoch 373, Accuracy: 1.0, Loss: 0.034432921558618546\n",
      "Epoch 374, Accuracy: 1.0, Loss: 0.034265320748090744\n",
      "Epoch 375, Accuracy: 1.0, Loss: 0.034099090844392776\n",
      "Epoch 376, Accuracy: 1.0, Loss: 0.033934179693460464\n",
      "Epoch 377, Accuracy: 1.0, Loss: 0.0337705984711647\n",
      "Epoch 378, Accuracy: 1.0, Loss: 0.033608317375183105\n",
      "Epoch 379, Accuracy: 1.0, Loss: 0.03344733268022537\n",
      "Epoch 380, Accuracy: 1.0, Loss: 0.03328762203454971\n",
      "Epoch 381, Accuracy: 1.0, Loss: 0.03312917426228523\n",
      "Epoch 382, Accuracy: 1.0, Loss: 0.03297198563814163\n",
      "Epoch 383, Accuracy: 1.0, Loss: 0.032816026359796524\n",
      "Epoch 384, Accuracy: 1.0, Loss: 0.03266129642724991\n",
      "Epoch 385, Accuracy: 1.0, Loss: 0.032507769763469696\n",
      "Epoch 386, Accuracy: 1.0, Loss: 0.03235546126961708\n",
      "Epoch 387, Accuracy: 1.0, Loss: 0.03220432251691818\n",
      "Epoch 388, Accuracy: 1.0, Loss: 0.0320543609559536\n",
      "Epoch 389, Accuracy: 1.0, Loss: 0.031905561685562134\n",
      "Epoch 390, Accuracy: 1.0, Loss: 0.031757909804582596\n",
      "Epoch 391, Accuracy: 1.0, Loss: 0.031611401587724686\n",
      "Epoch 392, Accuracy: 1.0, Loss: 0.031466007232666016\n",
      "Epoch 393, Accuracy: 1.0, Loss: 0.03132173791527748\n",
      "Epoch 394, Accuracy: 1.0, Loss: 0.031178560107946396\n",
      "Epoch 395, Accuracy: 1.0, Loss: 0.031036486849188805\n",
      "Epoch 396, Accuracy: 1.0, Loss: 0.030895480886101723\n",
      "Epoch 397, Accuracy: 1.0, Loss: 0.030755547806620598\n",
      "Epoch 398, Accuracy: 1.0, Loss: 0.030616674572229385\n",
      "Epoch 399, Accuracy: 1.0, Loss: 0.03047884814441204\n",
      "Epoch 400, Accuracy: 1.0, Loss: 0.03034205362200737\n",
      "Epoch 401, Accuracy: 1.0, Loss: 0.030206283554434776\n",
      "Epoch 402, Accuracy: 1.0, Loss: 0.03007153607904911\n",
      "Epoch 403, Accuracy: 1.0, Loss: 0.029937786981463432\n",
      "Epoch 404, Accuracy: 1.0, Loss: 0.029805034399032593\n",
      "Epoch 405, Accuracy: 1.0, Loss: 0.029673265293240547\n",
      "Epoch 406, Accuracy: 1.0, Loss: 0.02954246662557125\n",
      "Epoch 407, Accuracy: 1.0, Loss: 0.029412640258669853\n",
      "Epoch 408, Accuracy: 1.0, Loss: 0.029283761978149414\n",
      "Epoch 409, Accuracy: 1.0, Loss: 0.029155835509300232\n",
      "Epoch 410, Accuracy: 1.0, Loss: 0.029028845950961113\n",
      "Epoch 411, Accuracy: 1.0, Loss: 0.028902774676680565\n",
      "Epoch 412, Accuracy: 1.0, Loss: 0.028777632862329483\n",
      "Epoch 413, Accuracy: 1.0, Loss: 0.02865339256823063\n",
      "Epoch 414, Accuracy: 1.0, Loss: 0.028530044481158257\n",
      "Epoch 415, Accuracy: 1.0, Loss: 0.028407594189047813\n",
      "Epoch 416, Accuracy: 1.0, Loss: 0.028286036103963852\n",
      "Epoch 417, Accuracy: 1.0, Loss: 0.028165336698293686\n",
      "Epoch 418, Accuracy: 1.0, Loss: 0.02804550528526306\n",
      "Epoch 419, Accuracy: 1.0, Loss: 0.027926530689001083\n",
      "Epoch 420, Accuracy: 1.0, Loss: 0.027808407321572304\n",
      "Epoch 421, Accuracy: 1.0, Loss: 0.02769112028181553\n",
      "Epoch 422, Accuracy: 1.0, Loss: 0.02757466398179531\n",
      "Epoch 423, Accuracy: 1.0, Loss: 0.02745903842151165\n",
      "Epoch 424, Accuracy: 1.0, Loss: 0.027344223111867905\n",
      "Epoch 425, Accuracy: 1.0, Loss: 0.027230210602283478\n",
      "Epoch 426, Accuracy: 1.0, Loss: 0.027117004618048668\n",
      "Epoch 427, Accuracy: 1.0, Loss: 0.027004586532711983\n",
      "Epoch 428, Accuracy: 1.0, Loss: 0.026892956346273422\n",
      "Epoch 429, Accuracy: 1.0, Loss: 0.02678210660815239\n",
      "Epoch 430, Accuracy: 1.0, Loss: 0.02667202055454254\n",
      "Epoch 431, Accuracy: 1.0, Loss: 0.026562700048089027\n",
      "Epoch 432, Accuracy: 1.0, Loss: 0.02645413763821125\n",
      "Epoch 433, Accuracy: 1.0, Loss: 0.02634631283581257\n",
      "Epoch 434, Accuracy: 1.0, Loss: 0.026239242404699326\n",
      "Epoch 435, Accuracy: 1.0, Loss: 0.02613290771842003\n",
      "Epoch 436, Accuracy: 1.0, Loss: 0.026027292013168335\n",
      "Epoch 437, Accuracy: 1.0, Loss: 0.025922397151589394\n",
      "Epoch 438, Accuracy: 1.0, Loss: 0.02581821382045746\n",
      "Epoch 439, Accuracy: 1.0, Loss: 0.02571474201977253\n",
      "Epoch 440, Accuracy: 1.0, Loss: 0.025611966848373413\n",
      "Epoch 441, Accuracy: 1.0, Loss: 0.025509897619485855\n",
      "Epoch 442, Accuracy: 1.0, Loss: 0.025408504530787468\n",
      "Epoch 443, Accuracy: 1.0, Loss: 0.02530779503285885\n",
      "Epoch 444, Accuracy: 1.0, Loss: 0.02520775981247425\n",
      "Epoch 445, Accuracy: 1.0, Loss: 0.025108393281698227\n",
      "Epoch 446, Accuracy: 1.0, Loss: 0.025009695440530777\n",
      "Epoch 447, Accuracy: 1.0, Loss: 0.024911655113101006\n",
      "Epoch 448, Accuracy: 1.0, Loss: 0.02481425181031227\n",
      "Epoch 449, Accuracy: 1.0, Loss: 0.024717506021261215\n",
      "Epoch 450, Accuracy: 1.0, Loss: 0.024621395394206047\n",
      "Epoch 451, Accuracy: 1.0, Loss: 0.024525916203856468\n",
      "Epoch 452, Accuracy: 1.0, Loss: 0.02443106286227703\n",
      "Epoch 453, Accuracy: 1.0, Loss: 0.024336835369467735\n",
      "Epoch 454, Accuracy: 1.0, Loss: 0.024243222549557686\n",
      "Epoch 455, Accuracy: 1.0, Loss: 0.024150220677256584\n",
      "Epoch 456, Accuracy: 1.0, Loss: 0.024057824164628983\n",
      "Epoch 457, Accuracy: 1.0, Loss: 0.023966021835803986\n",
      "Epoch 458, Accuracy: 1.0, Loss: 0.02387482300400734\n",
      "Epoch 459, Accuracy: 1.0, Loss: 0.023784209042787552\n",
      "Epoch 460, Accuracy: 1.0, Loss: 0.023694178089499474\n",
      "Epoch 461, Accuracy: 1.0, Loss: 0.023604730144143105\n",
      "Epoch 462, Accuracy: 1.0, Loss: 0.02351585403084755\n",
      "Epoch 463, Accuracy: 1.0, Loss: 0.02342754229903221\n",
      "Epoch 464, Accuracy: 1.0, Loss: 0.02333979494869709\n",
      "Epoch 465, Accuracy: 1.0, Loss: 0.023252610117197037\n",
      "Epoch 466, Accuracy: 1.0, Loss: 0.023165974766016006\n",
      "Epoch 467, Accuracy: 1.0, Loss: 0.02307989075779915\n",
      "Epoch 468, Accuracy: 1.0, Loss: 0.022994352504611015\n",
      "Epoch 469, Accuracy: 1.0, Loss: 0.02290935069322586\n",
      "Epoch 470, Accuracy: 1.0, Loss: 0.022824883460998535\n",
      "Epoch 471, Accuracy: 1.0, Loss: 0.022740952670574188\n",
      "Epoch 472, Accuracy: 1.0, Loss: 0.022657541558146477\n",
      "Epoch 473, Accuracy: 1.0, Loss: 0.0225746501237154\n",
      "Epoch 474, Accuracy: 1.0, Loss: 0.02249227650463581\n",
      "Epoch 475, Accuracy: 1.0, Loss: 0.02241041325032711\n",
      "Epoch 476, Accuracy: 1.0, Loss: 0.02232905849814415\n",
      "Epoch 477, Accuracy: 1.0, Loss: 0.02224821224808693\n",
      "Epoch 478, Accuracy: 1.0, Loss: 0.022167859598994255\n",
      "Epoch 479, Accuracy: 1.0, Loss: 0.022088002413511276\n",
      "Epoch 480, Accuracy: 1.0, Loss: 0.022008635103702545\n",
      "Epoch 481, Accuracy: 1.0, Loss: 0.021929757669568062\n",
      "Epoch 482, Accuracy: 1.0, Loss: 0.02185135707259178\n",
      "Epoch 483, Accuracy: 1.0, Loss: 0.021773437038064003\n",
      "Epoch 484, Accuracy: 1.0, Loss: 0.021695991978049278\n",
      "Epoch 485, Accuracy: 1.0, Loss: 0.02161901630461216\n",
      "Epoch 486, Accuracy: 1.0, Loss: 0.021542510017752647\n",
      "Epoch 487, Accuracy: 1.0, Loss: 0.021466461941599846\n",
      "Epoch 488, Accuracy: 1.0, Loss: 0.021390873938798904\n",
      "Epoch 489, Accuracy: 1.0, Loss: 0.021315736696124077\n",
      "Epoch 490, Accuracy: 1.0, Loss: 0.021241063252091408\n",
      "Epoch 491, Accuracy: 1.0, Loss: 0.02116682194173336\n",
      "Epoch 492, Accuracy: 1.0, Loss: 0.021093029528856277\n",
      "Epoch 493, Accuracy: 1.0, Loss: 0.021019678562879562\n",
      "Epoch 494, Accuracy: 1.0, Loss: 0.020946763455867767\n",
      "Epoch 495, Accuracy: 1.0, Loss: 0.020874282345175743\n",
      "Epoch 496, Accuracy: 1.0, Loss: 0.020802229642868042\n",
      "Epoch 497, Accuracy: 1.0, Loss: 0.020730605348944664\n",
      "Epoch 498, Accuracy: 1.0, Loss: 0.020659394562244415\n",
      "Epoch 499, Accuracy: 1.0, Loss: 0.020588604733347893\n",
      "Epoch 500, Accuracy: 1.0, Loss: 0.020518232136964798\n"
     ]
    }
   ],
   "source": [
    "# 开始引用上面我们构造的函数进行训练啦,这相当于main()函数\n",
    "\n",
    "\n",
    "# pos_edge_list为正边(positive edge)的list\n",
    "pos_edge_list = graph_to_edge_list(G)\n",
    "# 将pos_edge_list转换成张量得到pos_edge_index\n",
    "pos_edge_index = edge_list_to_tensor(pos_edge_list)\n",
    "\n",
    "# 随机采样78条负边，neg_edge_list为负边的list\n",
    "neg_edge_list = sample_negative_edges(G, len(pos_edge_list))\n",
    "neg_edge_index = edge_list_to_tensor(neg_edge_list)\n",
    "\n",
    "# 产生正负标签\n",
    "pos_label = torch.ones(pos_edge_index.shape[1])\n",
    "neg_label = torch.zeros(neg_edge_index.shape[1] )\n",
    "\n",
    "# 将正负标签拼接成一个张量\n",
    "train_label = torch.cat([pos_label, neg_label], dim=0)\n",
    "\n",
    "# 将正负边拼接成一个张量\n",
    "train_edge = torch.cat([pos_edge_index, neg_edge_index], dim=1)\n",
    "\n",
    "# 训练更新节点嵌入\n",
    "loss_fn = nn.BCELoss()\n",
    "sigmoid = nn.Sigmoid()\n",
    "train(emb, loss_fn, sigmoid, train_label, train_edge)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
