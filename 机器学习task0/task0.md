##  问题回答： ##

#### 1.  #### 

​	_什么是机器学习？机器学习和深度学习有什么区别？_

> 结合西瓜书的概念，机器学习是一种研究如何通过复杂的计算手段，利用经验来反馈般的改善系统自身的性能的学科。机器学习的主要内容就是从数据中产生“学习算法”，使用我们的数据，样本来产生相应的判断，帮助我们做出决策。
>
> 深度学习是机器学习的一种特定方法，大部分深度学习模仿脑神经网络的结构和功能，通过构建多层神经网络来学习和表示数据的抽象特征。深度学习算法可以自动地从数据中学习到层次化的特征表示，无需手工设计。典型的深度学习就是很深层的神经网络。
>
> 区别:
>
> > 1.深度学习是机器学习的一个技术领域。
> >
> > 2.深度学习通常需要大量的训练数据和计算资源，并且往往需要更长的训练时间。而其他机器学习算法可以处理小规模数据集，并能够更快地训练和推理。
> >
> > 3.深度学习在处理图像、语音、自然语言处理等任务时通常表现出更强大的性能
>
> 

#### 2.  #### 

​	_请简述**监督学习与无监督学习**的概念，给出你对无监督学习和监督学习的自己理解和看法_

> 监督学习是指模型从带有标签的训练数据中学习，目标是通过输入数据预测相应的输出标签。训练数据由输入特征和相应的输出标签组成，通过训练使模型能够学习输入特征与输出标签之间的一些对应关系。然后，该模型可以用来对新的未标记数据进行预测。
>
> 相反的，无监督学习就是模型从未标记的训练数据中学习，目标是发现输入数据的内在结构、模式和关系。无监督学习算法试图在没有先验知识的情况下，自动地对数据进行聚类、降维、异常检测等操作，从而生成有关数据的有用信息。
>
> 我的理解和看法是，监督学习和无监督学习都是机器学习中两个重要的模型类。监督学习侧重于使用带有标签的数据来预测和分类，适用于有明确输出的问题，例如这次的MNIST手写数字分类、图像识别等。无监督学习则更侧重于从未标记的数据中发现模式和结构，适用于对数据进行聚类、异常检测等任务。



#### 3. ####

​	_**偏导数**是什么？**链式法则**是什么？**梯度**又是什么？**矩阵乘法**怎么操作？请仔细思考他们在机器学习/深度学习中的作用_

> （根据微积分（二））偏导数是多元函数中的一个概念，表示函数在某一变量上的变化率。对于一个多元函数，当其他自变量保持不变时，偏导数可以用来衡量其中一个自变量对函数值的影响程度。
>
> 链式法则是微积分中的一个计算规则，用于计算复合函数的导数。它描述了复合函数的导数与内外函数的导数之间的关系。通过链式法则，可以将复杂的函数求导问题简化为求解基本函数的导数。在机器学习里，偏导数是计算图参数更新的基础。
>
> 梯度是多元函数的一个概念，表示函数在某一点上的最大变化率和方向，它是一个向量，包含函数在各个变量上的偏导数。得知梯度我们就找到函数的最速下降方向，进而计算最大值、最小值或者局部极值。
>
> 矩阵乘法是运算中的一种运算方式，它是将两个矩阵按照一定规则进行乘法运算得到新的矩阵。计算结果矩阵的每一个数字都来自于前一个矩阵的行与后一矩阵的列对应相乘
>
> 在机器学习和深度学习中：
>
> > 1. 偏导数和链式法则用于求解损失函数关于模型参数的梯度，然后更新模型参数。借助他们，我们可以找到损失函数对于模型参数的梯度，进而根据梯度下降法来更新模型参数以最小化模型的损失函数。
> > 2. 梯度表示了函数在一点上的最大变化率和方向，可以用于指导参数优化的方向。在机器学习中，梯度可以告诉我们如何调整模型参数，使得损失函数最小化或目标函数最大化。
> > 3. 矩阵乘法在深度学习中被广泛应用，特别是在神经网络的前向传播和反向传播过程中。矩阵乘法可以高效地计算输入和权重之间的加权和，从而进行特征的线性组合。在反向传播过程中，通过链式法则，矩阵乘法可以将梯度传递回到前一层，以便进行参数的更新和优化。



#### 4. ####

​	_什么是**损失函数**？**梯度下降**的原理？**反向传播**的原理？_

> 损失函数是机器学习和深度学习中用来衡量模型预测结果与真实值之间的差异的函数。它会在训练过程中被优化。不同的问题和任务有不同的损失函数选择，例如均方误差用于回归问题，在这次招新多次出现的交叉熵（Cross Entropy）用于分类问题等。
>
> 梯度下降是一种优化算法，用于最小化损失函数。它基于函数的负梯度方向，通过迭代的方式找到损失函数的极值点。在模型计算过程中，梯度下降算法从一个初始点开始，在每一次迭代中根据负梯度的方向和学习率更新模型参数的值，使得损失函数逐渐减小。
>
> 反向传播是深度神经网络中的一种训练算法，用于计算网络参数的梯度。反向传播利用链式法则，从网络的输出层向输入层反向传播梯度，根据梯度对参数进行调整。



#### 5. ####

​	_什么是**样本**（sample）？什么是**特征**（feature）？为什么要使用**激活函数**？_

>   样本就是数据的承载者。一个样本包含若干个数据，也就是特征。多个样本构成作用于模型的训练集、测试集。
>
>   特征在训练集、测试集里表现为大量的数字。在现实生活中就如温度，湿度，颜色等，通过对现实生活中的这些“差别”的量化，我们就得到了特征值。同种特征之间的差异，不同特征之间或许存在着的函数关系，在模型中被或深或浅的学习，最终赋予了模型预测、分类的能力
>
>   激活函数如Pytorch中的Sigmoid，Tanh，ReLu等，他们都是非线性函数，引入了非线性性，如果没有他们，再复杂的线性神经网络，最终只是一层Y=KX+B；而有了激活函数，模型的输出才能千变万化，获得更多的表达能力；其中特殊的激活函数如sigmoid函数这类将输出限制在0~1的函数，更是让模型具备了输出概率的能力



#### 6. ####

​	_请简述**线性回归**和**逻辑回归**的概念与基本原理。通过学习，总结出线性回归和逻辑回归的联系与区别_

>   线性回归和逻辑回归都是机器学习中的算法。线性回归是通过模型拟合出一个Y=KX+B线性模型来预测目标变量的对应值。它假设自变量和目标变量间有线性关系，通过对残差平方和的计算来确定最佳直线
>
>   逻辑回归实际上不是回归而是分类问题。它使用逻辑函数（sigmoid等）将线性组合的结果映射到0~1之间的概率值，以此完成分类任务。
>
>   联系与区别：
>
>   > 二者都是监督学习算法，都包含回归分析的思想
>
>   > 线性回归用来预测连续数值的目标变量，二逻辑回归用来进行分类任务；线性回归输出的是目标变量值，逻辑回归输出的是目标变量属于某一个类别的概率并去最高概率类别作为结果



#### 7. ####

​	_在机器学习中，为什么要将**数据集**划分成**训练集、验证集和测试集**？三者之间区别与联系，以及数据集不正确划分造成的影响？我们该如何正确的划分和使用数据集？_

>  把数据集分成训练集、验证集和测试集是为了训练和评估监督学习模型的好坏。训练集用来训练模型，他应该包含足够的样本并广泛包含了数据的分布和特征。测试集用来评估模型的好坏和泛化能力，其也应该如训练集一样充足包含样本分布和特征且和训练集尽可能不重复或过于相似



#### 8. ####

​	_**softmax函数**是什么？其在机器学习中有什么应用？_

>  softmax是常用的激活函数之一，常用在多分类问题里面，他将任意实数映射到非负向量并进行归一化：
>  $$
>  \text{softmax}(x_i) = \frac{e^{x_i}}{\sum_{j=1}^{N} e^{x_j}}
>  $$
>  它在机器学习里面将模型的输出转换为概率分布，使模型能用于多分类问题，在神经网络里常用在输出层中。







